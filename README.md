# ğŸ“š RAG Pipeline â€“ Retrieval Augmented Generation

A complete Retrieval-Augmented Generation (RAG) pipeline built using Python, Groq LLM, LangChain / LangGraph, and a Vector Database to enable accurate, context-aware question answering over custom documents.

---

## ğŸš€ Features

- Load data from PDF / CSV / Text
- Text chunking and preprocessing
- Embeddings generation
- Persistent Vector Database (Chroma / FAISS)
- Semantic similarity search
- LLM-based answer generation using Groq (LLaMA)
- Optional conversational memory using LangGraph
- Secure API key handling with environment variables

---

## ğŸ§  What is RAG?

Retrieval-Augmented Generation (RAG) improves LLM responses by retrieving relevant information from a vector database and injecting it into the prompt before generating an answer.  
This reduces hallucinations and improves accuracy.

---

## ğŸ—ï¸ Architecture

User Query  
â†“  
Embedding Model  
â†“  
Vector Database  
â†“  
Relevant Chunks  
â†“  
Prompt + Context  
â†“  
Groq LLM  
â†“  
Final Answer  

---

## ğŸ“‚ Project Structure

RAG-Pipeline/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_docs/
â”‚   â””â”€â”€ vector_store/
â”‚
â”œâ”€â”€ Notebook/
â”‚   â””â”€â”€ RAG.ipynb 
|
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ§° Tech Stack

Language: Python  
LLM: Groq (LLaMA-3 / LLaMA-3.3)  
Framework: LangChain / LangGraph  
Vector DB: Chroma / FAISS  
Embeddings: Sentence Transformers  

---

## âš™ï¸ Installation

1. Clone repository

git clone https://github.com/TusharFodse/RAG-Pipeline.git  
cd RAG-Pipeline  

2. Create virtual environment

python -m venv venv  
venv\Scripts\activate  

3. Install dependencies

pip install -r requirements.txt  

---

## ğŸ” Environment Variables

Create a .env file:

GROQ_API_KEY=your_groq_api_key_here

Note: Never commit API keys to GitHub.

---

## â–¶ï¸ How to Run

Run using Jupyter Notebook:

jupyter notebook  
Open Notebook/RAG.ipynb  

OR

Run using Python:

python src/rag_pipeline.py  

---

## ğŸ§ª Example Query

Question: What is Encoder and Decoder in Deep Learning?

Answer:
The encoder converts input data into a compressed representation,
while the decoder reconstructs output from that representation.

---

## ğŸ§µ Conversational RAG (Optional)

Supports conversational memory using LangGraph to maintain context across multiple queries.

---

## ğŸ›¡ï¸ Security

- API keys stored in environment variables
- .env added to .gitignore
- GitHub push-protection safe

---

## ğŸ“ˆ Future Enhancements

- Web UI (Streamlit / React)
- Hybrid Search (BM25 + Vector)
- Re-ranking models
- Multi-document indexing
- Evaluation metrics

---

## ğŸ‘¨â€ğŸ’» Author

Tushar Fodse  
Aspiring AI / ML Engineer  

---

## ğŸ“œ License

MIT License

